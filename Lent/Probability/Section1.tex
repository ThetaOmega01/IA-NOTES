\section{Classical Probability}
\subsection{Probability Space}
\begin{definition}[Probability Space]
    Suppose $ \Omega $ is a set(called \textbf{sample space}) and $ \mathcal{F} $ is a collection of subsets of $ \Omega $. We call $\mcF$ a \textbf{$\sigma$-algebra} if 
    \begin{enumerate}
        \item $ \Omega\in \mathcal{F} $,
        \item $ A\in \mathcal{F} \Rightarrow A^\complement \in \mathcal{F} $,
        \item For any \textit{countable} collection $ (A_n)_{n\ge 1} $ with $A_n\in \mcF$, $ \bigcup_{n=1}^{\infty}A_n\in \mathcal{F} $.
    \end{enumerate}
    Suppose $\mcF$ is a $ \sigma $-algebra on $ \Omega $. A function $ \mathbb{P}:\mathcal{F}\to [0,1] $ is called a \textbf{probability measure} if
    \begin{enumerate}
        \item $ \bbP(\Omega)=1 $,
        \item For any \textit{countable disjoint} collection $ (A_n)_{n\ge 1} $ in $ \mathcal{F} $, 
        \[
            \mathbb{P}\left( \bigcup_{n=1}^{\infty}A_n \right) = \sum_{n=1}^{\infty} \mathbb{P}(A_n).
        \]
        We say $ \mathbb{P}(A) $ is the \textbf{probability} of $A$.
    \end{enumerate}
    We call $ (\Omega,\mathcal{F},\mathbb{P}) $ a \textbf{probability space}.
\end{definition}
\begin{remark}
    When $ \Omega $ is countable, we take $\mcF$ be all subsets of $ \Omega $.
\end{remark}
\begin{definition}[Outcomes, Events]
    The elements of $ \Omega $ are called \textbf{outcomes} and the elements of $\mcF$ are called \textbf{events}.
\end{definition}
\begin{remark}
    We talk about probabilities of \textit{events} rather than \textit{outcomes}.
\end{remark}
\begin{proposition}[Properties of $\bbP$]\label{prop:Properties of P}
    Immediate from the definition,
    \begin{itemize}
        \item $ \mathbb{P}(A^\complement) = 1 - \mathbb{P}(A) $.
        \item $ \mathbb{P}(\varnothing)=0 $.
        \item If $ A \subseteq B $, then $ \mathbb{P}(A) \le \mathbb{P}(B) $.
        \item $ \mathbb{P}(A \cup B) = \mathbb{P}(A)+\mathbb{P}(B)-\mathbb{P}(A \cap B) $.
    \end{itemize}
\end{proposition}
\begin{example}
    \underline{Rolling a fair die.} Here $ \Omega = \{1,2,3,4,5,6\}, \mathcal{F} = 2^\Omega $. For $ \omega\in \Omega$, $\mathbb{P}(\{\omega\})=1/6 $, and if $ A \subseteq \Omega, \mathbb{P}(A)=|A|/6 $, since all outcomes are \textit{equally likely}.
\end{example}
\begin{example}
    \underline{Equally likely outcomes.} Let $ \Omega = \{\omega_1,\dots, \omega_n\} $ be a finite set and $ \mathcal{F}=2^\Omega $. Define $\bbP$ as $ \mathbb{P}(A)=|A|/|\Omega| $. In classical probability, this models picking a random element of $ \Omega $. Note that $ \mathbb{P}(\{\omega\})=1/|\Omega|, \forall \omega\in \Omega $.
\end{example}
\begin{example}
    \underline{Picking balls from a bag.} Suppose we have $n$ balls with $n$ labels $ \{1,\dots,n\} $ so they are distinct. Pick $k\le n$ balls at ramdom \textit{without replacement}. Take $ \Omega = \{A \subseteq \{1,\dots,n\}: |A|=k\} $, so $ |\Omega|=\binom{n}{k} $. $ \mathbb{P}(\{\omega\}) = 1/|\Omega| = 1/\binom{n}{k} $.
\end{example}
\begin{example}
    \underline{Deck of cards.} Take a \textit{well-shuffled} deck of 52 cards. Well-shuffled means all possible permutations are equally likely. Let $ \Omega = \{\text{all permutations of 52 cards}\}, |\Omega|=52! $. Now $ \mathbb{P}(\text{top 2 cards are aces}) = 4 \cdot 3 \cdot 50!/52! = 1/221$.
\end{example}
\begin{example}
    \underline{Largest digit.} Consider a string of $n$ random digits from 0 to 9. $ \Omega = \{0,\dots,9\}^n $, $ |\Omega| = 10^n, \mathcal{F}=2^\Omega  $. Let 
    \[
         A_k = \{\text{no digit exceeds }k\}, B_k =\{\text{largest digit is }k\} .
    \]
    $ \mathbb{P}(B_k) = |B_k|/10^n $. Notice $ B_k = A_k \setminus A_{k-1} $ and $ |A_k| = (k+1)^n $, so $ |B_k|=(k+1)^n-k^n $, so $ \mathbb{P}(B_k) = \frac{(k+1)^n-k^n}{10^n} $.
\end{example}
\begin{example}
    \underline{Birthday problem.} There are $n$ people. What is the probability that at least 2 of them share the same birthday?\footnote{Assume that every year has 365 days. Also assume each birthday is equally likely.} So $ \Omega = \{1,\dots,365\}^n $, $ \mathcal{F} = 2^\Omega, \mathbb{P}(\{\omega\}) = 1/365^n $. Let 
    \[
        A=\{\text{at least 2 people share the same birthday}\} ,
    \]
     then $ A^\complement = \{\text{all birthdays are different}\} $ and since $ \mathbb{P}(A)=1-\mathbb{P}(A^\complement) $, it suffices to calculate $ \mathbb{P}(A^\complement) = |A^\complement|/|\Omega| = 365 \cdot 364 \cdot \cdots \cdot (365-n+1)/365^n $ and hence 
    \[
        \mathbb{P}(A) = 1-\frac{365 \cdot 364 \cdot \cdots \cdot (365-n+1)}{365^n}.
    \]
    Note that $n=22, \mathbb{P}(A) \approx 0.476$ and $ n=23, \mathbb{P}(A)\approx 0.507 $. 
\end{example}

\subsection{Combinatorial Analysis}

\begin{question}{1}
    Suppose $ |\Omega|=n $. Want to partition $ \Omega $ into $k$ \textit{disjoint} subsets $ \Omega_1,\dots,\Omega_k$, $ |\Omega_i|=n_i, \sum_{i=1}^{k}n_i=n $. How many ways are there to do so?
\end{question}

\begin{definition}[Multinomial Coefficient]
    Let $ M=\# \text{ of ways} $, then 
    \[
        M= \binom{n}{n_1}\cdots \binom{n-(n_1+\cdots+n_{k-1})}{n_k} = \frac{n!}{n_1!n_2!\cdots n_k!}
        =: \binom{n}{n_1,n_2,\dots,n_k}
    \]
    is called \textbf{multinomial coefficient} and it is the answer to the question above.
\end{definition}

\begin{question}{2}
    How many strictly increasing functions $ f: \{1,\dots,k\} \to \{1,\dots,n\}$ exist?
\end{question}

Any function is uniquely determined by its range which is a subset of $ \{1,\dots,n\} $ of size $k$. There are $ \binom{n}{k} $ such subsets, and hence $ \binom{n}{k} $ such functions.

\begin{question}{3}
    How many non-decreasing functions $ f: \{1,\dots,k\} \to \{1,\dots,n\}$ exist?
\end{question}

Define a bijection from $ \{f: \{1,\dots,k\}\to \{1,\dots,n\}: f \text{ is non-decreasing}\} $ to $ \{g: \{1,\dots,k\}\to \{1,\dots,n+k-1\}: g \text{ is strictly increasing}\} $. $ \forall f \nearrow $, define $ g(i)=f(i)+i-1 $. It is clear that $g$ is strictly increasing and takes values $ \{1,\dots,n+k-1\} $, and vice versa.
\begin{proposition}[Combination with Repetition]\label{prop:Combination with Repetition}
    The number of ways to choose $k$ items from $n$ items with repetition is 
    \[
        \binom{n+k-1}{n},
    \]
    and it is the answer to question 3.
\end{proposition}
\subsection{Stirling's Formula}
\textbf{Notation}. Let $(a_n),(b_n)$ be 2 sequences. We write 
\[
    a_n \sim b_n \text{ if } \frac{a_n}{b_n} \to 1 \text{ as }n \to \infty .
\]

\begin{theorem}[Stirling]\label{thm:stirling}
    $ n! \sim n^n \sqrt{2\pi n}e^{-n} $ as $n\to \infty$.
\end{theorem}

Weaker statement:
\begin{proposition}\label{prop:weak stirling}
    $ \log n! \sim n \log n $.
\end{proposition}
\begin{proof}
    Note that 
    \[
        l_n = \log n! = \sum_{k=1}^{n}\log k.
    \]
    Note that $ \log \lfloor x \rfloor \le \log x \le \log \lfloor x+1 \rfloor $. We have 
    \begin{align*}
        & \int_{1}^{n} \log \lfloor x \rfloor \,\mathrm{d}x \le \int_{1}^{n} \log x \,\mathrm{d}x \le \int_{1}^{n} \log \lfloor x+1 \rfloor \,\mathrm{d}x\\ 
        \Longrightarrow & \sum_{k=1}^{n-1}\log k\le n\log n-n+1\le \sum_{k=1}^{n} \log k\\ 
        \Longrightarrow & l_{n-1}\le n\log n-n+1\le l_n.
    \end{align*}
    Therefore, 
    \begin{align*}
        &n\log n-n+1\le l_n\le (n+1) \log (n+1) -n \\ 
        \Longrightarrow& 1- \frac{1-n}{n\log n}\le \frac{l_n}{n\log n}\le \frac{(n+1) \log (n+1)}{n\log n}-\frac{1}{\log n}\\ 
        \Longrightarrow & \frac{l_n}{n\log n} \to 1.
    \end{align*}
\end{proof}

\begin{lemma}\label{lma:stirling1}
    For any twice-differentiable function $f$, we have 
    \[
        \int_{a}^{b} f(x) \,\mathrm{d}x = \frac{f(a)+f(b)}{2}(b-a) - \frac{1}{2} \int_{a}^{b} (x-a)(b-x)f''(x) \,\mathrm{d}x.
    \]
\end{lemma}

\begin{proof}
    \begin{align*}
        \int_{a}^{b} (x-a)(b-x)f''(x) \,\mathrm{d}x &= \left[ (x-a)(b-x)f'(x) \right]_{a}^{b} - \int_{a}^{b} (-2x+a+b) f'(x) \,\mathrm{d}x\\ 
        &= \left[ (2x-a-b)f(x) \right]_{a}^{b} - \int_{a}^{b} 2f(x) \,\mathrm{d}x\\ 
        &= (f(a)+f(b))(a+b) - 2 \int_{a}^{b} f(x) \,\mathrm{d}x.
    \end{align*}
    The result follows.
\end{proof}

\begin{lemma}\label{lma:stirling2}
    $\displaystyle 2^{-2n}\binom{2n}{n}\sim \frac{1}{\sqrt{\pi n}}$. 
\end{lemma}
\begin{proof}
    Consider 
    \[
        I_n = \int_{0}^{\frac{\pi}{2}} \cos^n \theta \,\mathrm{d}\theta,
    \]
    so $I_0=\frac{\pi}{2}, I_1=1$. Note that 
    \begin{align*}
        I_n &= \left[ \sin \theta \cos^{n-1} \theta \right]_{0}^{\frac{\pi}{2}} + (n-1)\int_{0}^{\frac{\pi}{2}} \cos^{n-2} \theta(1-\cos^2 \theta) \,\mathrm{d}\theta\\ 
        &= (n-1)(I_{n-2}-I_{n}),
    \end{align*}
    so
    \[
        I_n = \frac{n-1}{n}I_{n-2},
    \]
    and
    \[
        I_{2n} = \frac{2n-1}{2n}I_{2n-2} = \cdots = \frac{(2n)!/(2^n n!)}{2^n n!} I_0 = \frac{(2n)!}{2^{2n} (n!)^2}\frac{\pi}{2}=2^{-2n}\binom{2n}{n}\frac{\pi}{2}.
    \]
    Similarly,
    \[
        I_{2n+1} = \frac{1}{2n+1} \cdot \left( 2^{-2n}\binom{2n}{n} \right)^{-1}.
    \]

    From $I_n = \frac{n-1}{n}I_{n-2}$ we see $ I_n/I_{n-2}\to 1 $. Notice that $I_n$ is decreasing wrt $n$, so 
    \[
        \frac{I_{2n}}{I_{2n+1}}\le \frac{I_{2n-1}}{I_{2n+1}}\to 1
    \]
    and also 
    \[
        \frac{I_{2n}}{I_{2n+1}}\ge \frac{I_{2n}}{I_{2n-2}}\to 1,
    \]
    so by sandwich theorem, $ I_{2n}/I_{2n+1}\to 1$, which means 
    \begin{align*}
        &2^{-2n}\binom{2n}{n}\frac{\pi}{2} \sim \frac{1}{2n+1} \cdot \left( 2^{-2n}\binom{2n}{n} \right)^{-1}\\ 
        \Longrightarrow & \left( 2^{-2n}\binom{2n}{n} \right)^2 \sim \frac{2}{(2n+1)\pi} \sim \frac{1}{\pi n}\\ 
        \Longrightarrow & 2^{-2n}\binom{2n}{n} \sim \frac{1}{\sqrt{\pi n}},
    \end{align*}
    as required.
\end{proof}

\begin{proof}[Proof of Stirling's theorem]
    Consider 
    \begin{align*}
        \int_{k}^{k+1} \log x \,\mathrm{d}x &= \frac{\log k+ \log (k+1)}{2} + \frac{1}{2} \int_{k}^{k+1} \frac{(x-k)(k+1-x)}{x^2} \,\mathrm{d}x\\ 
        &= \frac{\log k+ \log (k+1)}{2} + \frac{1}{2} \int_{0}^{1} \frac{x(1-x)}{(x+k)^2} \,\mathrm{d}x.
    \end{align*}
    This holds by lemma \ref{lma:stirling1} and change of variable. Summing over $1$ to $n-1$ we get 
    \begin{align*}
        \int_{1}^{n} \log x \,\mathrm{d}x &= \frac{\log(n-1)!+\log n!}{2} + \sum_{k=1}^{n-1}\underbrace{\frac{1}{2}\int_{0}^{1} \frac{x(1-x)}{(x+k)^2} \,\mathrm{d}x}_{a_k}\\ 
        \Longrightarrow &n\log n-n+1 = \log n! - \frac{\log n}{2} + \sum_{k=1}^{n-1}a_k\\ 
        \Longrightarrow & \log n! = n\log n-n+1+\frac{\log n}{2}-\sum_{k=1}^{n-1}a_k\\ 
        \Longrightarrow & n! = n^n e^{-n} \sqrt{n} \exp\left( 1- \sum_{k=1}^{n-1}a_k\right).
    \end{align*}

    Note that 
    \[
        a_k\le \frac{1}{2}\int_{0}^{1} \frac{x(1-x)}{k^2} \,\mathrm{d}x = \frac{1}{12k^2},
    \]
    so $ \sum a_k$ converges. Let $ A = \exp\left( 1- \sum_{k=1}^{\infty}a_k\right) $, then 
    \[
        n! = n^n e^{-n} \sqrt{n} A \exp \left( \sum_{k=n}^{\infty}a_k \right),
    \]
    so 
    \[
        \frac{n!}{n^n e^{-n} \sqrt{n}} \to A \Longleftrightarrow n! \sim n^n e^{-n} \sqrt{n}\cdot A.
    \]
    To finish the proof we need to show $ A=\sqrt{2\pi} $. Note that 
    \[
        2^{-2n}\binom{2n}{n} = 2^{-2n}\frac{(2n)!}{(n!)^2}\sim \frac{(2n)^{2n} e^{-2n} \sqrt{2n}\cdot A}{(n^n e^{-n} \sqrt{n}\cdot A)^2} = \frac{\sqrt{2}}{A\sqrt{n}}.
    \]
    On the other hand, by lemma \ref{lma:stirling2} we have 
    \[
        2^{-2n}\binom{2n}{n}\sim \frac{1}{\sqrt{\pi n}},
    \]
    so $ A=\sqrt{2\pi} $ and
    \[
        n! \sim n^n \sqrt{2\pi n}e^{-n},
    \]
    as claimed.
\end{proof}

\subsection{Properties of probability measures}

Let $ (\Omega,\mathcal{F},\mathbb{P}) $ be a probability space.

\begin{proposition}[Countable subadditivity]\label{prop:Countable subadditivity}
    Let $ (A_n)_{n\ge 1} $ be a sequence of events in $ \mathcal{F} $, then 
\[
    \mathbb{P}\left( \bigcup_{n=1}^{\infty}A_n \right)\le \sum_{n=1}^{\infty}\mathbb{P}(A_n).
\]
\end{proposition}
\begin{proof}
    Define 
    \[
        B_1=A_1 \text{ and } B_n = A_n \setminus \left( \bigcup_{k=1}^{n-1}A_k \right)\text{ for }n\ge 2.
    \]
    Then $ (B_n)_{n\ge 1} $ is a disjoint sequence of events in $ \mathcal{F} $. Also
    \[
        \bigcup_{n=1}^{\infty}A_n=\bigcup_{n=1}^{\infty}B_n,
    \]
    so that
    \[
        \mathbb{P}\left( \bigcup_{n=1}^{\infty}A_n \right) = \mathbb{P}\left( \bigcup_{n=1}^{\infty}B_n \right).
    \]
    
    Note that 
    \[
        \mathbb{P}\left( \bigcup_{n=1}^{\infty}B_n \right) = \sum_{n=1}^{\infty}\mathbb{P}(B_n).
    \]
    But $ B_n \subseteq A_n $, so $ \mathbb{P}(B_n)\le \mathbb{P}(A_n) $, and thus 
    \[
        \mathbb{P}\left( \bigcup_{n=1}^{\infty}A_n \right) = \mathbb{P}\left( \bigcup_{n=1}^{\infty}B_n \right)=\sum_{n=1}^{\infty}\mathbb{P}(B_n)\le \sum_{n=1}^{\infty}\mathbb{P}(A_n),
    \]
    as required.
\end{proof}

\begin{proposition}[Continuity]\label{prop:continuity}
    Let $A_n$ be an increasing sequence in $ \mathcal{F} $: $ A_{n}\in \mathcal{F} \land A_n \subseteq A_{n+1} $, then $ \mathbb{P}(A_n) \le \mathbb{P}(A_{n+1}) $ so $ \mathbb{P}(A_n) $ converges. We have
    \[
        \lim_{n \to \infty} \mathbb{P}(A_n) = \mathbb{P}\left( \bigcup_{n=1}^{\infty}A_n \right).
    \]
\end{proposition}
\begin{proof}
    Define 
    \[
        B_1=A_1 \text{ and } B_n = A_n \setminus \left( \bigcup_{k=1}^{n-1}A_k \right)\text{ for }n\ge 2.
    \]
    Then $ A_n = \bigcup_{k=1}^{n}B_k $ and $ \bigcup_{k=1}^{\infty}B_k= \bigcup_{k=1}^{\infty}A_k$. Hence 
    \[
        \mathbb{P}(A_n) = \mathbb{P}\left( \bigcup_{k=1}^{n}B_k \right) = \sum_{k=1}^{n}\mathbb{P}(B_k)\to \sum_{k=1}^{\infty}\mathbb{P}(B_k).
    \]
    On the other hand,
    \[
        \mathbb{P}\left( \bigcup_{k=1}^{\infty}A_k \right)=\mathbb{P}\left( \bigcup_{k=1}^{\infty}B_k \right) = \sum_{k=1}^{\infty}\mathbb{P}(B_k).
    \]
    The result follows.
\end{proof}

Similarly 
\begin{corollary}\label{col:continuity2}
    If $ A_n $ is a \textit{decreasing} sequence in $ \mathcal{F} $, then 
    \[
        \mathbb{P}(A_n)\to \mathbb{P}\left( \bigcap_{n=1}^{\infty}A_n \right).
    \]
\end{corollary}
\begin{proof}
    Set $ A_n' = A_n^{\complement} $ in proposition \ref{prop:continuity}.
\end{proof}

\begin{proposition}[Inclusion-exclusion formula]\label{prop:Inclusion-exclusion formula}
    Let $ A_1,A_2, \dots, A_n\in \mathcal{F} $, then 
    \begin{align*}
        \mathbb{P}\left( \bigcup_{i=1}^{n}A_i \right) &= \sum_{i=1}^{n}\mathbb{P}(A_i) - \sum_{i_1<i_2} \mathbb{P}(A_{i_1}\cap A_{i_2})+\sum_{i_1<i_2<i_3}\mathbb{P}(A_{i_1}\cap A_{i_2}\cap A_{i_3})\\ 
        &-\cdots+ (-1)^{n+1} \mathbb{P}(A_1 \cap \cdots \cap A_n)\\ 
        &=\sum_{k=1}^{n}(-1)^{k+1} \sum_{i_1<i_2<\cdots<i_k}\mathbb{P}\left( A_{i_1}\cap \cdots \cap A_{i_k} \right).
    \end{align*}
\end{proposition}
\begin{proof}[Proof by induction]
    It holds for $n=2$. Assume it holds $n-1$ events, note that 
    \begin{align*}
        \mathbb{P}(A_1 \cup \cdots \cup A_n)&= \mathbb{P}\left( (A_1 \cup \cdots \cup A_{n-1}) \cup A_n \right)\\ 
        &= \mathbb{P}(A_1 \cup \cdots \cup A_{n-1})+\mathbb{P}(A_n)-\mathbb{P}((A_1 \cup \cdots \cup A_{n-1})\cap A_n)\\ 
        &= \mathbb{P}(A_1 \cup \cdots \cup A_{n-1})+\mathbb{P}(A_n)-\mathbb{P}(\cup_i (A_i\cap A_n)).
    \end{align*}
    Set $ B_i=A_i\cap A_n $. By the induction hypothesis,
    \[
        \mathbb{P}(\cup A_i)=\sum_{k=1}^{n-1}(-1)^{k+1} \sum_{i_1<i_2<\cdots<i_k}\mathbb{P}\left( A_{i_1}\cap \cdots \cap A_{i_k} \right)
    \]
    and 
    \[
        \mathbb{P}(\cup B_i)=\sum_{k=1}^{n-1}(-1)^{k+1} \sum_{i_1<i_2<\cdots<i_k}\mathbb{P}\left( B_{i_1}\cap \cdots \cap B_{i_k} \right).
    \]
    Substituting back proves the theorem.
\end{proof}
\begin{corollary}\label{col:inclusion-exclusion2}
        Let $ (\Omega,\mathcal{F},\mathbb{P}) $ with $ |\Omega|<\infty  $ and $ \mathbb{P}(A)=|A|/|\Omega| $. Let $ A_1,\dots,A_n\in \mathcal{F} $, then 
        \[
            \left| \bigcup_{i=1}^{n}A_i \right| = \sum_{k=1}^{n}(-1)^{k+1} \sum_{i_1<i_2<\cdots<i_k}\left| A_{i_1}\cap \cdots \cap A_{i_k} \right|.
        \]
\end{corollary}

\begin{proposition}[Bonferroni inequalities]\label{prop:Bonferroni inequalities}
    If $r$ is odd, then 
    \[
        \mathbb{P}\left( \bigcup_{i=1}^{n}A_i \right)\le \sum_{k=1}^{r}(-1)^{k+1} \sum_{i_1<i_2<\cdots<i_k}\mathbb{P}\left( A_{i_1}\cap \cdots \cap A_{i_k} \right).
    \]
    If $r$ is even, then 
    \[
        \mathbb{P}\left( \bigcup_{i=1}^{n}A_i \right)\ge \sum_{k=1}^{r}(-1)^{k+1} \sum_{i_1<i_2<\cdots<i_k}\mathbb{P}\left( A_{i_1}\cap \cdots \cap A_{i_k} \right).
    \]
\end{proposition}
\begin{proof}[Proof by induction]
    Clearly $ \mathbb{P}(A \cup B)\le \mathbb{P}(A)+\mathbb{P}(B) $. Assume it holds for $n-1$ events.

    Suppose $r$ is odd. Then 
    \[
        \mathbb{P}(A_1 \cup \cdots \cup A_n) = \mathbb{P}(A_1 \cup \cdots \cup A_{n-1})+\mathbb{P}(A_n)-\mathbb{P}(B_1 \cup \cdots \cup B_{n-1})
    \]
    where $ B_i=A_i\cap A_n $. We have 
    \[
        \mathbb{P}\left( \bigcup_{i=1}^{n-1}B_i \right)\ge \sum_{k=1}^{r-1}(-1)^{k+1} \sum_{i_1<i_2<\cdots<i_k}\mathbb{P}\left( B_{i_1}\cap \cdots \cap B_{i_k} \right).
    \]
    Therefore 
    \[
        \mathbb{P}\left( \bigcup_{i=1}^{n}A_i \right)\le \sum_{k=1}^{r}(-1)^{k+1} \sum_{i_1<i_2<\cdots<i_k}\mathbb{P}\left( A_{i_1}\cap \cdots \cap A_{i_k} \right),
    \]
    as claimed. It is similar if $r$ is even.
\end{proof}

\begin{example}
    Number of surjections $ f: \{1,\dots,n\}\to \{1,\dots,m\} $.

    Let $ \Omega = \{f: \{1,\dots,n\}\to \{1,\dots,m\}\} $ and $ A=\{f\in \Omega: f \text{ is a surjection}\} $. Given $ i\in \{1,\dots,m\} $, define $ A_i=\{f\in\Omega: i\notin \{f(1),\dots,f(n)\}\} $. Then 
    \[
        A = (A_1 \cup \cdots \cup A_m)^{\complement}.
    \]
    Hence 
    \begin{align*}
        |A|&= |\Omega|-|A_1 \cup \cdots \cup A_m|=m^n-|A_1 \cup \cdots \cup A_m|\\ 
        &= m^n-\sum_{k=1}^{m}(-1)^{k+1} \sum_{i_1<i_2<\cdots<i_k}\left| A_{i_1}\cap \cdots \cap A_{i_k} \right|\\ 
        &= m^n-\sum_{k=1}^{m}(-1)^{k+1} \binom{m}{k}(m-k)^n\\ 
        &= \sum_{k=0}^{m}(-1)^k \binom{m}{k}(m-k)^n.
    \end{align*}
\end{example}

\begin{example}[Counting derangements]
    Let $ \Omega=\{\text{permutations of }\{1,\dots,n\}\} $, and
    \[
        A = \{f\in\Omega: f(i)\neq i, \forall i\}.
    \]
    Pick a permutation at random. What is the probability it is in $A$?

    Define $ A_i = \{f\in \Omega: f(i)=i\} $, then 
    \[
        A=\bigcap A_i^{\complement} = \Omega\setminus \bigcup A_i \quad \text{and}\quad \mathbb{P}(A)=1-\mathbb{P}\left( \bigcup A_i \right).
    \]
    Note that 
    \begin{align*}
        \mathbb{P}\left( \bigcup A_i \right)&= \sum_{k=1}^{n}(-1)^{k+1} \sum_{i_1<i_2<\cdots<i_k}\mathbb{P}\left( A_{i_1}\cap \cdots \cap A_{i_k} \right)\\ 
        &= \sum_{k=1}^{n}(-1)^{k+1}\binom{n}{k}\frac{(n-k)!}{n!}\\ 
        &= \sum_{k=1}^{n}(-1)^{k+1}\frac{1}{k!},
    \end{align*}
    and thus 
    \[
        \mathbb{P}(A) = 1+\sum_{k=1}^{n}(-1)^{k}\frac{1}{k!} = \sum_{k=0}^{n}\frac{(-1)^k}{k!}\to e^{-1}\approx 0.3678.
    \]
\end{example}

\subsection{Independence}

\begin{definition}[Independence]
    Let $ A,B\in \mathcal{F} $. They are called \textbf{independent} ($ A \independent B $) if 
    \[
        \mathbb{P}(A \cap B) = \mathbb{P}(A)\mathbb{P}(B).
    \]

    A \textit{countable} collection of events $ (A_n) $ is said to be independent if for any $ i_1,\dots,i_k $ distinct, we have 
    \[
        \mathbb{P}(A_{i_1}\cap \cdots A_{i_k}) = \prod_{j=1}^{k}\mathbb{P}(A_{i_j}).
    \]
\end{definition}
\begin{remark}
    \textit{Pairwise} independence \textit{does not} imply independence. Toss a fair coin twice. Note that.
    \[
        \Omega=\{(0,0),(0,1),(1,0),(1,1)\}, \mathbb{P}(\{\omega\})=\frac{1}{4}.
    \]
    Define $ A=\{(0,0),(0,1)\} $, $ B=\{(0,0),(0,1)\} $ and $ C=\{(1,0),(0,1)\} $. Then $ \mathbb{P}(A)=\mathbb{P}(B)=\mathbb{P}(C)=\frac{1}{2} $. It can be checked that $A,B,C$ are pairwise independent. However $ A \cap B \cap C= \varnothing  $ so $ \mathbb{P}(A \cap B \cap C)=0 $, and thus $A,B,C$ are not independent.
\end{remark}

\begin{claim}
    If $A$ is independent of $B$, then $A$ is also independent of $ B^\complement $.
\end{claim}
\begin{proof}
    $ \mathbb{P}(A\cap B^\complement)=\mathbb{P}(A)-\mathbb{P}(A \cap B)  =\mathbb{P}(A)(1-\mathbb{P}(B))=\mathbb{P}(A)\mathbb{P}(B^\complement) $.
\end{proof}

\begin{definition}[Conditional probability]
    Let $ B\in \mathcal{F} $ with $ \mathbb{P}(B)>0 $, and $ A\in \mathcal{F} $. Define the \textit{conditional probability} of $A$ given $B$ by 
    \[
        \mathbb{P}(A|B)=\frac{\bbP(A\cap B)}{\bbP(B)}.
    \]
    If $ A \independent B $, then $ \mathbb{P}(A|B)=\mathbb{P}(A) $.
\end{definition}

\begin{proposition}[Countable additivity for conditional probability]\label{prop:Countable additivity for conditional probability}
    Suppose $ (A_n) $ is a disjoint sequence in $ \mcF $. Then 
    \[
        \mathbb{P}\left( \bigcup_{n=1}^{\infty}A_n\Big|B \right) = \sum_{n=1}^{\infty}\mathbb{P}(A_n|B).
    \]
\end{proposition}
\begin{proof}
    \[
        \mathbb{P}(\cup A_n|B) = \frac{\mathbb{P}((\cup A_n)\cap B)}{\bbP(B)} = \frac{\bbP(\cup(A_n\cap B))}{\mathbb{P}(B)}=\sum_{n=1}^{\infty}\frac{\bbP(A_n\cap B)}{\mathbb{P}(B)}=\sum_{n=1}^{\infty}\mathbb{P}(A_n|B).
    \]
\end{proof}

\begin{proposition}[Law of total probability]\label{prop:Law of total probability}
    Suppose $ (B_n)_{n\ge 1} $ is a disjoint collection in $ \mathcal{F} $, $ \cup B_n=\Omega $ and $ \forall n, \mathbb{P}(B_n)>0 $. Let $ A\in \mathcal{F} $. Then 
    \[
        \bbP(A)=\sum_{n=1}^{\infty}\mathbb{P}(A|B_n)\mathbb{P}(B_n).
    \]
\end{proposition}
\begin{proof}
    \begin{align*}
        \mathbb{P}(A)&= \mathbb{P}(A\cap \Omega) = \mathbb{P}(A\cap (\cup B_n))\\ 
        &= \mathbb{P}(\cup (A\cap B_n)) = \sum_{n=1}^{\infty} \mathbb{P}(A\cap B_n)=\sum_{n=1}^{\infty}\mathbb{P}(A|B_n)\mathbb{P}(B_n).
    \end{align*}
\end{proof}

\begin{corollary}[Bayes' formula]\label{thm:Bayes' formula}
    If: disjoint $ (B_n)_{n\ge 1} $, $ \cup B_n=\Omega $, $ \mathbb{P}(B_n)>0, \forall n $, then 
    \[
        \mathbb{P}(B_n|A) = \frac{\mathbb{P}(A|B_n)\mathbb{P}(B_n)}{\sum_{k=1}^{\infty}\mathbb{P}(A|B_k)\mathbb{P}(B_k)}.
    \]
\end{corollary}
\begin{proof}
    \[
        \mathbb{P}(B_n|A) = \frac{\bbP(B_n\cap A)}{\bbP(A)}= \frac{\mathbb{P}(A|B_n)\mathbb{P}(B_n)}{\sum_{k=1}^{\infty}\mathbb{P}(A|B_k)\mathbb{P}(B_k)}.
    \]
\end{proof}
This formula is the basis of Bayesian statistics. We know the probabilities of the events $ B_k $ and we have a model which gives $ \mathbb{P}(A|B_n) $. Bayes' formula tells how to calculate the posterior probabilities of $ B_n $ given $A$.

\begin{example}[False positive for a rare condition]
    Suppose that a disease $A$ affects 0.1\% of the poplulation. We have a medical test which is positive for 98\% of the affected population and 1\% of the unaffected population. Pick an individual at random. What is the probability they has $A$ given that they are positive?

    Define 
    \[
        A = \{\text{individuals with A}\},\quad P=\{\text{individuals tested positive}\},
    \]
    want to find $\bbP(A|P)$. Note that $ \mathbb{P}(A)=0.001, \mathbb{P}(P|A) = 0.98, \mathbb{P}(P|A^\complement)=0.01 $. By Bayes' formula,
    \[
        \mathbb{P}(A|P) = \frac{\mathbb{P}(P|A)\mathbb{P}(A)}{\mathbb{P}(P|A)\mathbb{P}(A)+\mathbb{P}(P|A^\complement)\mathbb{P}(A^\complement)} \approx 0.09.
    \]
    This is quite low since $ \mathbb{P}(P|A^\complement)\gg \mathbb{P}(A) $.
\end{example}
\begin{example}
    We have 3 statements:
    \begin{enumerate}[(a).]
        \item I have 2 children, one of whom is a boy.
        \item I have 2 children, the eldest is a boy.
        \item I have 2 children, one of whom is a boy born on a Thursday.
    \end{enumerate}
    Let $ A = \{\text{I have 2 boys}\} $. Then $\mathbb{P}(A|a) = \frac{1}{3},\mathbb{P}(A|b) = \frac{1}{2}$, and 
    \[
        \mathbb{P}(A|c) = \frac{\frac{1}{4}\times \frac{1}{49}+2 \times \frac{1}{4}\times \frac{6}{49}}{\frac{1}{4}\times \frac{1}{49}+2 \times \frac{1}{4}\times \frac{6}{49}+\frac{1}{2}\times \frac{1}{7}} = \frac{13}{27}.
    \]
\end{example}
\begin{example}[Simpson's paradox]
    There are $50$ men and $50$ women applying to a college.
    \begin{center}
        \begin{tabular}{|c|c|c|c|}
            \hline
            All applicants&Admitted&Rejected&Success Rate\\
            \hline
            State&25&25&50\%\\
            Indep&28&22&56\%\\
            \hline
            Men Only&Admitted&Rejected&Success Rate\\
            \hline
            State&15&22&41\%\\
            Indep&5&8&38\%\\
            \hline
            Women Only&Admitted&Rejected&Success Rate\\
            \hline
            State&10&3&77\%\\
            Indep&23&14&68\%\\ 
            \hline
        \end{tabular}
    \end{center}
    This phenomenon is called \textbf{confounding} in statistics. It arises when we aggregate data from disparate populations. Let $ A = \{\text{individual is admitted}\} $, $ B = \{\text{individual is a man}\} $, and $ C = \{\text{individual comes from a state school}\} $. We see that 
    \[
        \mathbb{P}(A|B \cap C)>\mathbb{P}(A|B \cap C^\complement)\quad \text{and}\quad \mathbb{P}(A|B^\complement \cap C)> \mathbb{P}(A| B^\complement \cap C^\complement),
    \]
    but $ \mathbb{P}(A|C^\complement)>\mathbb{P}(A|C) $. Note that
    \begin{align*}
        \mathbb{P}(A|C) &= \mathbb{P}(A \cap B|C)+\mathbb{P}(A \cap B^\complement|C)\\ 
        &= \frac{\bbP(A\cap B\cap C)}{\bbP(C)}+\frac{\bbP(A\cap B^\complement\cap C)}{\bbP(C)}\\ 
        &= \mathbb{P}(A|B\cap C)\mathbb{P}(B|C)+\mathbb{P}(A|B^\complement \cap C)\mathbb{P}(B^\complement|C)\\ 
        &> \mathbb{P}(A|B\cap C^\complement)\mathbb{P}(B|C)+\mathbb{P}(A|B^\complement \cap C^\complement)\mathbb{P}(B^\complement|C).
    \end{align*}
    \textit{Assume} further that $ \mathbb{P}(B|C) = \mathbb{P}(B|C^\complement) $, then $ \mathbb{P}(A|C)>\mathbb{P}(A|C^\complement) $. However, in this case it is not true that $ \mathbb{P}(B|C) = \mathbb{P}(B|C^\complement) $, so we see $ \mathbb{P}(A|C^\complement)>\mathbb{P}(A|C) $.
\end{example}