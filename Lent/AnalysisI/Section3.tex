\section{Differentiability}
\subsection{Several definitions}
\begin{definition}
    Let $ f:E \subseteq \mathbb{C} \to \mathbb{C}  $. Let $ x $ be a limit point. $f$ is said to be \textbf{differentiable} at $x$ with \textbf{derivative} $f'(x)$ if 
    \[
        \lim_{y \to x} \frac{f(y)-f(x)}{y-x} = f'(x).
    \]
    If $f$ is differentiable on every point in $E$, then $f$ is differentiable on $E$. (Think $E$ as an interval or a disc)
\end{definition}
\begin{remark}
    Other common notations are $\frac{\mathrm{d}y}{\mathrm{d}x},\frac{\mathrm{d}f}{\mathrm{d}x},\text{ etc.}  $.
    Note also that 
    \[
        f'(x) = \lim_{h \to 0} \frac{f(x+h)-f(x)}{h}.
    \]
\end{remark}
\begin{remark}
    ``Another look'' at the definition: Let 
    \[
        \epsilon(h) = f(x+h)-f(x)-hf'(x),
    \]
    then $ \lim_{h \to 0} \frac{\epsilon(h)}{h}=0 $ and thus 
    \[
        f(x+h) = f(x)+hf'(x)+\epsilon(h).
    \]
\end{remark}
\begin{definition}[Alternative definition]
    $f$ is differentiable at $x$ if $ \exists A,\epsilon $ that 
    \[
        f(x+h) = f(x)+hA+\epsilon(h),\quad \lim_{h \to 0} \frac{\epsilon(h)}{h}=0.
    \]
\end{definition}
\begin{note}
    If such $A$ exists then it is unique, since 
    \[
        A = \lim_{h \to 0} \frac{f(x+h)-f(x)}{h}. 
    \]
\end{note}
\begin{remark}
    Another alternative way of writing things is 
    \[
        f(x+h) = f(x)+hf'(x)+h\epsilon_f(h),\quad \epsilon_f(h)\to 0 \text{ as }h\to 0,
    \]
    or 
    \[
        f(x) = f(a)+(x-a)f'(a)+(x-a)\epsilon_f(x), \quad \lim_{x \to a} \epsilon_f(x)=0.
    \]
\end{remark}
\begin{sprop}
    If $f$ is differentiable at $x$, then it is continuous at $x$. 
\end{sprop}
\begin{proof}
    Refer to the alternative definition.
\end{proof}

\begin{example}
    Take $f(x)=|x|$. Clearly $f'(x)=1$ if $x>0$, $f'(x)=-1$ if $x=-1$. Take $ h_n\downarrow 0 $,
    \[
        \lim_{n \to \infty} \frac{f(h_n)-0}{h_1}=1,
    \]
    but with $ h_n \uparrow 0 $,
    \[
        \lim_{n \to \infty} \frac{f(h_n)-0}{h_n}=-1.
    \]
    Hence $f$ is not differentiable at $x=0$.
\end{example}
\subsection{Arithmetic of differentiation}
\begin{proposition}
    \begin{enumerate}
        \item If $f(x)=c,x\in E$, then $f$ is differentiable and $f'(x)=0$.
        \item If $f,g$ are differentialbe at $x$, then $f+g$ is differentiable with
        \[
            (f(x)+g(x))' = f'(x)+g'(x).
        \]
        \item If $f,g$ are differentialbe at $x$, then $f\cdot g$ is differentiable with
        \[
            (f(x)g(x))'=f'(x)g(x)+f(x)g'(x).
        \]
        \item If $f$ is differentiable at $x$ and $ \forall x\in E,f(x)\neq 0 $, then $ 1/f $ is differentiable with 
        \[
            \left( \frac{1}{f(x)} \right)' = -\frac{f'(x)}{f(x)^2}.
        \]
        \item If $f,g$ are differentialbe at $x$, then $f/ g$ is differentiable with
        \[
            \left( \frac{f(x)}{g(x)} \right)' = \frac{f'(x)g(x)-f(x)g'(x)}{g(x)^2}.
        \]
    \end{enumerate}
\end{proposition}
\begin{proof}
    1-3 are trivial and 5 is a consequence of 3 and 4, so we only prove 4 here. Let $ \phi(x) = 1/f(x) $. 
    \begin{align*}
        \frac{\phi(x+h)-\phi(x)}{h} &= \frac{1/f(x+h)-1/f(x)}{h}=\frac{f(x)-f(x+h)}{hf(x)f(x+h)}  \\ 
        &= \frac{f(x)-f(x+h)}{h}\cdot \frac{1}{f(x)f(x+h)}\\ 
        &\to -\frac{f'(x)}{f(x)^2}.\qedhere
    \end{align*} 
\end{proof}

\begin{example}
    Let $ f(x) = x^n, n\in \mathbb{Z}, n>0 $. If $n=1$, clearly $f(x)=x,f'(x)$=1. Claim that $ f'(x) = nx^{n-1} $. Note that $ f'(x) = (x \cdot x^{n})' = x^{n}+nx^{n-1} \cdot x = (n+1) x^{n} $, so it follows inductively. 
\end{example}
\begin{example}
    Let $ f(x) = x^{-n},n\in \mathbb{N} $. It can be checked that $ f'(x)=-nx^{-n-1} $.
\end{example}
By using proposition \ref{prop:2.1}, we know how to differentiate polynomials and rational functions.

\begin{theorem}[Chain rule]\label{thm:Chain rule}
    Let $ f:U\to \mathbb{C}  $ such that $ f(x)\in V,\forall x\in U $. If $f$ is differentiable at $a\in U$ and $ g:V\to \mathbb{C} $ is differentiable at $f(a)\in V$, then $g\circ f$ is differentiable at $x=a$ and
    \[
        (g \circ f)'(a) = g'(f(a))f'(a).
    \]
\end{theorem}
\begin{proof}
    Since $f$ is differentiable at $a$, we have 
    \[
        f(x) = f(a) + (x-a) f'(x) +\epsilon_f(x)(x-a),
    \]
    and since $g$ is differentiable at $b=f(a)$, 
    \[
        g(y) = g(b) + (y-b) g'(b) + \epsilon_g(y) (y-b).
    \]
    Set $ \epsilon_f(a)=\epsilon_g(b)=0 $ to make them continuous at $a,b$. Substituting $y=f(x)$ gives 
    \begin{align*}
        g(f(x)) &= g(b) + (f(x)-b)g'(b)+\epsilon_g(f(x))(f(x)-b)\\ 
        &= g(b) + ((x-a)f'(x)+\epsilon_f(x)(x-a))(g'(b)+\epsilon_g(f(x))) \\ 
        &= g(f(a)) + (x-a) f'(a)g'(b)+(x-a)\sigma(x),
    \end{align*} 
    where
    \[
        \sigma(x) = \epsilon_f(x)g'(b)+\epsilon_g(f(x))(f'(a)+\epsilon_f(x)).
    \]
    Now 
    \begin{align*}
        \lim_{x \to a} \sigma(x) &= \lim_{x \to a}\epsilon_f(x)g'(b)+\lim_{x \to a}\epsilon_g(f(x))(f'(a)+\epsilon_f(x))\\ 
        &=\lim_{x \to a}\epsilon_g(f(x))\lim_{x \to a}(f'(a)+\epsilon_f(x))\\ 
        &= 0.
    \end{align*}
    Hence $ \sigma(x) $ is of the form in the alternative definition, and thus 
    \[
        (g \circ f)'(x)=g'(f(x))f'(x),
    \]
    as required.
\end{proof}
\begin{example}
    $ \sin (x^2)'=2x \cos (x^2) $.
\end{example}
\begin{example}
    Let 
    \[
        f(x) = \begin{cases}
        x\sin(1/x) &\text{if }x\neq 0\\
        0 &\text{if }x=0\\
        \end{cases} 
    \]
    It is continuous on $\mathbb{R}$. By previous result, $f(x)$ is differentiable on $ \mathbb{R}\setminus \{0\} $. At $x=0$, 
    \[
        \frac{f(x)-f(0)}{x-0} = \sin (1/x),
    \]
    which has no limit as $ x\to 0 $. Therefore $f$ is \textit{not} differentiable at $0$.
\end{example}
\subsection{Theorems of differentiation}
\begin{theorem}[Rolle]\label{thm:Rolle}
    Suppose $ f:[a,b]\to \mathbb{R} $ is continuous on $[a,b]$ and differentiable on $(a,b)$. If $f(a)=f(b)$, then $ \exists c\in (a,b) $ such that $f'(c)=0$. 
\end{theorem}
\begin{proof}
    Let $ M=\max_{x\in [a,b]}f(x),m=\min_{x\in [a,b]}f(x) $. From theorem \ref{thm:continuous function attachs the bounds} we know that $M,m$ are indeed achieved. Let $k=f(a)$. If $M=m=k$, then $f$ is constant so clearly there is a $c$ that $f'(c)=0$. Hence $ M>k $ or $ m<k $. Suppose $M>k$. $ \exists c\in (a,b), f(c)=M $. Claim that $f'(c)=0$. If $f'(c)> 0$ wlog, then
    \[
        f(c+h) -f(c) = h(f'(c)+\epsilon(h)).
    \]
    For $h$ positive and small, $\text{RHS}>0$ and thus $ \exists h+c>c,f(h+c)>f(c) $, contradiction. Similarly for $f'(c)<0$.
\end{proof}
\begin{theorem}[Mean Value Theorem]\label{thm:Mean Value Theorem}
    Let $ f:[a,b]\to \mathbb{R} $ be continuous on $[a,b]$ and differentiable on $(a,b)$. Then $ \exists c\in (a,b) $ such that 
    \[
        f(b)-f(a) = f'(c)(b-a).
    \]
\end{theorem}
\begin{proof}
    Apply Rolle's theorem on 
    \[
        \phi(x) = f(x) - \frac{f(b)-f(a)}{b-a} x.\footnote{This can be obtained by considering $ \phi(x)=f(x)-kx $ such that $ \phi(a)=\phi(b) $.}\qedhere
    \]
\end{proof}
\begin{remark}
    We will often write
    \[
        f(a+h)=f(a)+hf'(a+\theta h),\quad 0<\theta<1.
    \]
\end{remark}

\begin{corollary}\label{col:3.5}
        If $ f:[a,b]\to \mathbb{R} $ is continuous on $[a,b]$ and differentiable on $(a,b)$, then 
        \begin{enumerate}
            \item If $ f'(x)>0,\ \forall x\in (a,b) $, then $f$ is strictly increasing on $[a,b]$.
            \item If $ f'(x)\ge0,\ \forall x\in (a,b) $, then $f$ is increasing.
            \item If $ f'(x)\equiv 0 $, then $f$ is constant. 
        \end{enumerate}
\end{corollary}
\begin{proof}
    These are immediate from MVT.
\end{proof}

\begin{theorem}[Inverse function theorem]\label{thm:Inverse function theorem}
    If $ f:[a,b]\to \mathbb{R}  $ is continuous on $[a,b]$ and differentiable on $ (a,b) $ with $ f'(x)>0 $. Let $f(a)=c,f(b)=d$. Then the function $ f:[a,b]\to [c,d] $ is bijective and $ f^{-1} $ is differentiable on $(c,d)$ with 
    \[
        (f^{-1})'(x)=\frac{1}{f'(f^{-1}(x))}.
    \]
\end{theorem}
\begin{proof}
    By corollary \ref{col:3.5} $f$ is strictly increasing on $[a,b]$. By theorem \ref{thm:existence of inverse function} $ \exists g:[c,d]\to [a,b] $ which is continuous strictly increasing inverse of $f$. If $k\neq 0$ is given, let $ h $ be such that $ y+k = f(x+h) \Leftrightarrow g(y+k)=x+h $, $ h\neq 0 $. Then 
    \[
        \frac{g(y+k)-g(y)}{k} = \frac{x+h-x}{f(x+h)-f(x)}= \frac{h}{f(x+h)-f(x)}.
    \]
    Note that since $g$ is continuous, $ h\to 0 $ as $ k\to 0 $. Hence
    \[
        g'(y) = \lim_{k \to 0} \frac{g(y+k)-g(y)}{k} = \lim_{h \to 0} \frac{h}{f(x+h)-f(x)} = \frac{1}{f'(x)}.\qedhere
    \]
\end{proof}
\begin{example}
    Let $ g(x)=x^{1/n},x>0,n\in \mathbb{N} $. $ g^{-1}(x)=x^{n} $, so
    \[
        g'(x) = 1/(g^{-1})'(x)=\frac{1}{n}x^{\frac{1}{n}-1}.
    \]
    More generally,
    \[
        \left( x^{p/q} \right)'=\frac{p}{q}x^{p/q-1},\quad p,q\in \mathbb{Z}.
    \]
\end{example}

Suppose $ f,g: [a,b] \to \mathbb{R} $ are continuous on $[a,b]$ and differentiable on $(a,b)$ and $g(a)\neq g(b)$. Then MVT gives that $ \exists s,t\in (a,b) $ such that 
\[
    \frac{f(b)-f(a)}{g(b)-g(a)}=\frac{(b-a)f'(s)}{(b-a)g'(t)}=\frac{f'(s)}{g'(t)}.
\]
Cauchy showed that one can take $s=t$.
\begin{theorem}[Cauchy's MVT]\label{thm:Cauchy}
    Let $f,g:[a,b]\to \mathbb{R}$ be continuous on $[a,b]$ and differentiable on $(a,b)$, then $ \exists t\in (a,b) $ such that 
    \[
        (f(b)-f(a))g'(t)=f'(t)(g(b)-g(a)).
    \]
\end{theorem}
\begin{note}
    We recover MVT if take $g(x)=x$.
\end{note}
\begin{proof}
    Let 
    \[
        \phi(x) = \begin{vmatrix}
            1 & 1 & 1 \\
            f(a) & f(x) & f(b) \\
            g(a) & g(x) & g(b) \\
        \end{vmatrix}.
    \]
    Then $ \phi(x) $ is continuous on $[a,b]$ and differentiable on $(a,b)$. Also $ \phi(a)=\phi(b)=0 $. By Rolle's theorem, $ \exists t\in(a,b) $ such that $ \phi'(t)=0 $, thus gives the result.
\end{proof}
\begin{example}[L'H\^{o}pital's rule]
    Find the limit of 
    \[
        \lim_{x \to 0} \frac{e^x-1}{\sin x}.
    \]
    By Cauchy's MVT, $\exists t$ that
    \[
        \frac{e^x-e^0}{\sin x-\sin 0} = \frac{e^t}{\cos t}.
    \]
    As $x\to 0$, $t\to 0$ and the limit is 1.
\end{example}

\subsubsection*{Extension to higher order derivatives}
\begin{theorem}[Taylor's theorem with Lagrange remainder]\label{thm:Taylor}
    Suppose $f$ and its derivatives up to order $n-1$ are continuous on $[a,a+h]$ and $ f^{(n)} $ exists for $ x\in (a,a+h) $. Then 
    \begin{align*}
        f(a+h) &= f(a)+hf'(a) +\cdots+\frac{h^{n-1}}{(n-1)!}f^{(n-1)}(a)+\frac{h^n}{n!}f^{(n)}(a+\theta h)\\ 
        &= \sum_{k=0}^{n-1}\frac{h^k}{k!}f^{(k)}(a)+ \underbrace{\frac{h^n}{n!}f^{(n)}(a+\theta h)}_{R_n} ,\quad \theta\in (0,1).
    \end{align*}
\end{theorem}
\begin{note}
    \begin{enumerate}
        \item For $n=1$, it is exactly the MVT. In this sense, it is a $n$th order MVT.
        \item $R_n$ is known as Lagrange's remainder.
    \end{enumerate}
\end{note}
\begin{proof}
    Define for $0\le t\le h$
    \[
        \phi(t) = f(a+t)-\sum_{k=0}^{n-1}\frac{t^k}{k!}f^{(k)}(a)-\frac{t^n}{n!}B\tag{$*$}
    \]
    where $B$ is chosen such that $\phi(h)=0$\footnote{Recall in the proof of MVT that we used $ f(x)-kx $ to apply Rolle's theorem.}. Then 
    \[
        \phi(0) = \phi'(0)= \cdots = \phi^{(n-1)}(0)=0.
    \]
    By using Rolle's theorem on $ \phi^{(k)}(0) $ and $ \phi^{(k)}(h) $ for all $k$, $ \exists \phi^{(k)}(h_k)=0, \forall k $. Hence at the final step, $ \exists h_n, 0<h_n<h_{n-1}<\cdots<h_1<h $ such that $ \phi^{(n)}(h_n)=0 $. Clearly we can write $ h_n = \theta h $ for $ \theta\in (0,1) $, so 
    \[
        \phi^{(n)}(\theta h) = f^{(n)}(a+\theta h)-B=0 \Longrightarrow B=f^{(n)}(a+\theta h).
    \]
    Setting $ t=h,\phi(h)=0, B=f^{(n)}(a+\theta h) $ in ($*$) gives the proof.
\end{proof}

\begin{theorem}[Taylor's theorem with Cauchy's remainder]\label{thm:Taylor,Cauchy remainder}
    With the same hypotheses as in theorem \ref{thm:Taylor} and (wlog) $a=0$, we have 
    \[
        f(h) = \sum_{k=0}^{n-1}\frac{h^k}{k!}f^{(k)}(0)+\underbrace{\frac{h^n(1-\theta)^{n-1}}{(n-1)!}f^{(n)}(\theta h)}_{R_n},\quad \theta\in (0,1).
    \]
\end{theorem}

\begin{proof}
    Define for $ t\in [0,h] $ 
    \[
        F(t) = f(h)-\sum_{k=0}^{n-1}\frac{t^k}{k!}f^{(k)}(t).
    \]
    Check that 
    \[
        F'(t) = - \frac{(h-t)^{n-1}}{(n-1)!}f^{(n)}(t).
    \]
    Set 
    \[
        \phi(t) = F(t) - \left( \frac{h-t}{h} \right)^p F(0),\quad \mathbb{N}\ni p \in [1,n].
    \]
    Check that $ \phi(0)=\phi(h)=0 $. By Rolle's theorem, $ \exists \theta\in (0,1), \phi'(\theta h)=0$. Hence
    \begin{align*}
        &\phi'(\theta h) = F'(\theta h) +\frac{p(1-\theta)^{p-1}}{h} F(0)=0\\ 
        \xRightarrow{\text{check}} &R_n=\frac{h^n(1-\theta)^{n-1}}{(n-1)!p(1-\theta)^{p-1}}f^{(n)}(\theta h).
    \end{align*}
    If $p=n$ we get Lagrange and if $p=1$ we get Cauchy.
\end{proof}
\begin{remark}
    \begin{align*}
        &\text{Lagrange's remainder}\qquad  \frac{h^n}{n!}f^{(n)}(a+\theta h)\\ 
        &\text{Cauchy's remainder}\qquad  \frac{h^n(1-\theta)^{n-1}}{(n-1)!}f^{(n)}(\theta h)
    \end{align*}
\end{remark}
\begin{remark}
    These 2 theorems work equally well in $ [a+h,a],h<0 $.
\end{remark}
\begin{example}[Binomial series]
    Let $ f(x) = (1+x)^r,r\in \mathbb{Q} $. Then if $ |x|<1 $, 
    \[
        (1+x)^r = 1 + \binom{r}{1}x+ \cdots + \binom{r}{n}x^n+ \cdots ,
    \]
    where the binomial coefficients are extended to $\mathbb{Q}$ in the usual way.
\end{example}
\begin{proof}[Indeed,]
    $ f^{(n)}(x) = r(r-1)\cdots (r-n+1)(1+x)^{r-n} $. If $ r\in \mathbb{Z},r\ge 0 $, then $ f^{(r+k)}=0,\forall k\ge 1 $, so we have a polynomial of degree $r$. If otherwise, in general
    \[
        R_n = \frac{x^n}{n!}f^{(n)}(\theta x) = \binom{r}{n}\frac{x^n}{(1+\theta x)^{n-r}}.
    \]
    Note that in principle $ \theta=\theta(x,n) $. 
    
    For $ 0<x<1, (1+\theta x)^{n-r}>1 $ for $n>r$. Note also that the series $ \sum_{n=0}^{\infty}\binom{r}{n}x^n $ converges absolutely for $ |x|<1 $. Indeed, it can be checked by ratio test. Hence $ \binom{r}{n}x^n<1 $ for $ |x|<1 $. Hence for $n>r$ and $0<x<1$ we have 
    \[
        |R_n|\le \left| \binom{r}{n}x^n \right|\to 0. 
    \]
    So the claim is proved for $ 0<x<1 $.

    If $ -1<x<0 $, the above argument does not work, so we try Cauchy's form.
    \begin{align*}
        R_n &= \frac{(1-\theta)^{n-1}}{(n-1)!}r(r-1)\cdots (r-n+1)(1+\theta h)^{r-n}x^n\\ 
        &= \frac{r(r-1)\cdots (r-n+1)}{(n-1)}\frac{(1-\theta)^{n-1}}{(1+\theta x)^{n-r}}x^n\\ 
        &=  r \binom{r-1}{n-1}x^n \cdot \frac{(1-\theta)^{n-1}}{(1+\theta x)^{n-r}}\\ 
        &= r \binom{r-1}{n-1}x^n \cdot(1+\theta x)^{r-1}\left( \frac{1-\theta}{1+\theta x} \right)^{n-1}
    \end{align*}
    Hence
    \[
        \left| R_n \right| \le \left| r\binom{r-1}{n-1}x^n \right| (1+\theta x)^{r-1} {\color{blue}\overset{\text{check}}{<}}  \left| r\binom{r-1}{n-1}x^n \right| \max \{1,(1+x)^{r-1}\}.
    \]
    Let $ K_r = |r| \max \{1,(1+x)^{r-1}\} $, so that $K_r$ is \textit{independent} from $n$. Hence 
    \[
        |R_n|\le K_r \left| \binom{r-1}{n-1}x^n \right| \to 0.
    \]
    Hence $ R_n\to 0 $ if $|x|<1$, as claimed.
\end{proof}

\subsection{Remarks on complex differentiation}
Formally we have the same properties regarding sums, products, and chain rule, etc. But it is \textit{much more} restrictive than differentiability of functions on the real line.

\begin{example}
    Let $ f(z) = \bar{z} $. Claim that $f$ is \textit{nowhere} differentiable. Take $ z_n=z+\frac{1}{n}\to z $, then 
    \[
        \frac{f(z_n)-f(z)}{z_n-z}\equiv 1.
    \]
    If take $ z_n = z+\frac{i}{n} $, then 
    \[
        \frac{f(z_n)-f(z)}{z_n-z}\equiv -1.
    \]
    Hence $f$ is nowhere differentiable. On the other hand, $ f(x,y)= (x,-y) $ is certainly differentiable. See IB Complex Analysis.
\end{example}